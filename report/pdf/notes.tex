\documentclass[12pt]{article}
%\usepackage{apacite}
\usepackage{wrapfig}
\setlength{\parindent}{0pt}
\usepackage{tgtermes}
\usepackage{setspace}
\usepackage{gensymb}
\doublespacing
\usepackage{graphicx}
\usepackage{float}
\usepackage[utf8]{inputenc}
\usepackage[backend=biber,style=apa,autocite=inline]{biblatex}
\usepackage{fancyhdr}
\pagestyle{fancy}
\lhead{Paper 1}
\rhead{Victor M. Poulsen, Studie Nr.: 201707639}

\DeclareLanguageMapping{english}{english-apa}
\addbibresource{References.bib}
%\setcounter{page}{3}

\title{Human Computer Interaction}
\author{Victor MÃ¸ller Poulsen, Studie Nr.: 201707639}

\begin{document}
\maketitle
\leavevmode

\section{Introduction}

\section{Target group}

Most specifically students at cognitive science who have learned
bayesian statistics in R/brms/stan but would like to transition
to python/pymc3/theano, or simply to learn how to conduct a bayesian
analysis in a second coding language. The workflow attempts to blend what has been
taught by Riccardo in the course computational modeling for cognitive
science, the workflow proposed by Gelman (ref) and what is recommended
as best practise in various pyMC3 tutorials (and the like). While
cognitive science students are my main demographic, this is a very
narrow target group. The notebook should be general enough that
everyone who is looking to transition from R/brms to python/pyMC3
should find the webpage useful.

Python is developing rapidly in data science and statistical analysis,
and while R has been dominant for specifically statistical analysis
this is not so clear anymore (ref??).

As I have tried to highlight in the webpage (product) I find that certain
things are easier in R/brms and certain things are easier in python/pyMC3.
One thing that I find easier in python/pyMC3 is doing customized analysis.
This is because R/stan relies on the easy-to-use model formula that is well known
from lme4 (see image). In Python/pyMC3 this has also been developed as
part of the glm module (right?) but the usual way is to explicitly connect the
building blocks (distributions) manually within a model context.
Besides allowing for easy customizability this also ensures that we actually
understand how our model works and what we are doing, which I think is
positive.


\section{What we have to include (notes)}

\begin{enumerate}
	\item Get predictions to work \\
	\item Draw our own Gelman \\
	\item Re-write to use dataframe in models (pyMC3) \\
	\item updating checks \\
	\item check nice tweaks (e.g. plot forest). \\
	\item re-run R models to get same number of samples as python. \\
	\item test that it looks OK with chains from R and add to multilevel
		and student.
	\item make reference list in the bottom for people who want to go
		further. \\
	\item remember to comment on the levels of uncertainty
		(e.g. both something in recoded and the online thread). \\
	\item something about that people should contact with feedback,
		suggestions and comments.
\end{enumerate}

\section{Good points we need to remember}

usability vs functionality, e.g.
\begin{enumerate}
	\item pop-out (e.g. the think deeper sections) \\
	\item not presenting all priors (not that important), but for those
		interested they can get it. Does not clutter the page. \\
	\item Focus on the target group, e.g. trying to make the python format
		as easy as possible while still remaining true to the format.
		E.g. avoid object oriented programming in my code-base,
		work as much as possible with data frames rather than raw
		vectors (which is typical in pyMC3 actually). Trying to make
		the material easy to digest for the target group while not
		compromizing with functionality (of the code). They can dive
		deeper on their own after this introduction. \\
	\item streamlit is most used in datascience and machine learning (ML)
		with models that fit really fast (i.e. < 1 second). streamlit
		presentations that rely on models of this kind can let the user
		freely play around with models, variables, etc. and fit the
		models in real time, thus making them really interactive.
		Since we cannot sample Bayesian models within a reasonable time-frame
		(i.e. it takes > 30 seconds) I had to think of alternatives
		to make the streamlit app feel interactive without requiring
		the user to wait excessively long. This was done by
		pre-rendering (bla, bla, bla \ldots leads to code base in next
		section).
\end{enumerate}

Design, e.g.
\begin{enumerate}
	\item Difference between pop-out (e.g. think deeper) and
		the buttons (e.g. prior levels). \\
	\item Nice color theme, to get them interested. \\
	\item Visually oriented. Focus on figures for the main page,
		and then a lot of the code and writing in optional boxes.
		Focus on just showing the workflow (keeping it simple) and
		then referring them to other more "deep" places. \\
\end{enumerate}

\section{Code base \& Reproducibility}

A lot of the development time for this project was spent ensuring a
solid code-base. This was necessary for two reasons.

First, because I had to pre-compile a lot of models and plots,
I had to make sure that my code was reproducible, without bugs,
and was possible to navigate. This was necessary from a developmental
point of view (i.e. it was necessary for me).

Second, it also means that the naming schemes for everything -
across R and Python and all parts of the analysis is consistent,
and that it should be easy for users to navigate the code-base.
I.e. those users who want to look deeper than just the streamlit app
and actually check the github.

\section{Conclusion}

\section{References}

Burkner talk: https://www.youtube.com/watch?v=1qeXD4NQ4To
* more on brms
* more on loo (out of sample predictions).

\section{early thoughts}
Generally for writing:

## python usage
tried to strike a balance between (a) optimal code practise
in python and (b) what is accessible for the students.
I.e. it should not be necessary to be a python genious to follow along.
For instance, I chose to not implement all of this as a class,
since object oriented programming is unfamiliar for most of
the students in the target group.

## pymc3 vs. brms
it stands to reason that the workflow in brms and in pymc3
is not the same. I.e., some things are easier/more natural in pymc3 (python) and
some things are easier/more natural in brms (R).
In these cases I have tried to strike a balance between not presenting
a markedly worse workflow as compared to what is possible, but keeping
the parallels between pymc3 and brms pretty direct.

## how it is intended to be used
(1) recalling how to do things. just quickly looking in to find something.
(2) read once as a pretty deep primer to start pymc3 from R.

remember to show the "easy" glm


\section{more thoughts}

1. you can copy the code to clipboard (workflow).
implemented with st.code() in streamlit.
unfortunately only python syntax highlighting,
but it still looks decent I think..
could have considered to break the code up
into more chunks so as to explain them step-by-step.
Depends on scope though - I would probably only have
had time to cover one model (i.e. either pooled or multilevel).

difficult decision:
what to force users to see, and what to
leave optional. Depends on the point of course.
My point is (1) to introduce how to technically
implement the same analysis in python that we
know how to implement in R (thus I should force
them to see the code). Only second is my point
to discuss with them why different models, priors
and technicalities are important (thus this is
in pop-out sections). Explanations for code is
also largely in optional sections. This makes it
easy for people to revisit and copy the code
without having to see the explanations again
if they do not feel like they need to.

difficult decision 2:
explaining how to use the product,
or hoping that it is intuitive enough that
people will just naturally figure it out?

2. orange punkter i python?

3. issue: multilevel specific HDI?
mean based on parameters??
mean appears to be the same for all model
types in python..?

4. hard-set x \& y on the plots.

5. uncertainty does not spread out for pooled.

6. set good base-line settings for what is
displayed.

\section{todo}

1. correct format for the trace (has to be the same)
2. reproducibility for prior plots (not as important).

\printbibliography
\end{document}


